{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.utils.Bunch'>\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris_data = load_iris()\n",
    "print(type(iris_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename'])\n"
     ]
    }
   ],
   "source": [
    "keys = iris_data.keys()\n",
    "print(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype='<U10')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_data.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sepal length (cm)',\n",
       " 'sepal width (cm)',\n",
       " 'petal length (cm)',\n",
       " 'petal width (cm)']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_data.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [5.4, 3.4, 1.5, 0.4],\n",
       "       [5.2, 4.1, 1.5, 0.1],\n",
       "       [5.5, 4.2, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [4.9, 3.6, 1.4, 0.1],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [5.1, 3.4, 1.5, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [5.5, 2.3, 4. , 1.3],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [6.7, 3.1, 4.4, 1.4],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [5.5, 2.4, 3.7, 1. ],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [6. , 2.7, 5.1, 1.6],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [5.6, 3. , 4.1, 1.3],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [6.3, 3.3, 6. , 2.5],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [7.1, 3. , 5.9, 2.1],\n",
       "       [6.3, 2.9, 5.6, 1.8],\n",
       "       [6.5, 3. , 5.8, 2.2],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [6.7, 2.5, 5.8, 1.8],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [6.5, 3.2, 5.1, 2. ],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [5.7, 2.5, 5. , 2. ],\n",
       "       [5.8, 2.8, 5.1, 2.4],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [6. , 2.2, 5. , 1.5],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [5.6, 2.8, 4.9, 2. ],\n",
       "       [7.7, 2.8, 6.7, 2. ],\n",
       "       [6.3, 2.7, 4.9, 1.8],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [7.2, 3.2, 6. , 1.8],\n",
       "       [6.2, 2.8, 4.8, 1.8],\n",
       "       [6.1, 3. , 4.9, 1.8],\n",
       "       [6.4, 2.8, 5.6, 2.1],\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [6.3, 2.8, 5.1, 1.5],\n",
       "       [6.1, 2.6, 5.6, 1.4],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [6. , 3. , 4.8, 1.8],\n",
       "       [6.9, 3.1, 5.4, 2.1],\n",
       "       [6.7, 3.1, 5.6, 2.4],\n",
       "       [6.9, 3.1, 5.1, 2.3],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [6.7, 3. , 5.2, 2.3],\n",
       "       [6.3, 2.5, 5. , 1.9],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [5.9, 3. , 5.1, 1.8]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_data.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 학습 / 테스트 데이터 세트 분리 - train_test_split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 아래와 같이 train_data 와 test_data 를 나누지 않으면 정확도를 예측할 수 없다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 정확도: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "iris = load_iris()\n",
    "df_clf = DecisionTreeClassifier()\n",
    "train_data = iris.data\n",
    "train_label = iris.target\n",
    "df_clf.fit(train_data, train_label)\n",
    "\n",
    "pred = df_clf.predict(train_data) # 위와 같이 train_data 와 test_data 를 나누지 않으면 정확도를 예측할 수 없다..predict(train_data)\n",
    "print(\"예측 정확도:\", accuracy_score(train_label, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 정확도: 0.9555555555555556\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_clf = DecisionTreeClassifier()\n",
    "iris_data = load_iris()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris_data.data, iris_data.target, test_size = 0.3, random_state=1)\n",
    "\n",
    "df_clf.fit(X_train, y_train)\n",
    "pred = df_clf.predict(X_test)\n",
    "print(\"예측 정확도:\", accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 교차검증"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "붓꽃 데이터 세트 크기: 150\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "iris = load_iris()\n",
    "features = iris.data\n",
    "label = iris.target\n",
    "dt_clf = DecisionTreeClassifier(random_state=156)\n",
    "\n",
    "# 5 개의 폴드 세트로 분리하는 KFold 객체와 폴드 세트별 정확도를 담을 리스트 객체 생성.\n",
    "kfold = KFold(n_splits=5)\n",
    "cv_accuracy = []\n",
    "print(\"붓꽃 데이터 세트 크기:\", features.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1 교차 검증 정확도 :1.0, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
      "#1 검증 세트 인덱스:[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29]\n",
      "\n",
      "2 교차 검증 정확도 :1.0, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
      "#2 검증 세트 인덱스:[30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53\n",
      " 54 55 56 57 58 59]\n",
      "\n",
      "3 교차 검증 정확도 :1.0, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
      "#3 검증 세트 인덱스:[60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83\n",
      " 84 85 86 87 88 89]\n",
      "\n",
      "4 교차 검증 정확도 :1.0, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
      "#4 검증 세트 인덱스:[ 90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119]\n",
      "\n",
      "5 교차 검증 정확도 :1.0, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
      "#5 검증 세트 인덱스:[120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "\n",
      "## 평균 검증 정확도: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\k58m\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:67: FutureWarning: Pass normalize=4 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "c:\\users\\k58m\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:67: FutureWarning: Pass normalize=4 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "c:\\users\\k58m\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:67: FutureWarning: Pass normalize=4 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "c:\\users\\k58m\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:67: FutureWarning: Pass normalize=4 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "c:\\users\\k58m\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:67: FutureWarning: Pass normalize=4 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    }
   ],
   "source": [
    "n_iter = 0\n",
    "\n",
    "# KFold 객체의 split() 를 호출하면 폴드 별 학습용, 검증용 테스트의 로우 인덱스를 array 로 변환.\n",
    "for train_index, test_index in kfold.split(features):\n",
    "    #kfold.split() 으로 반환된 인덱스를 이용해 학습용, 검증용 테스트 데이터 추출\n",
    "    X_train, X_test = features[train_index], features[test_index]\n",
    "    y_train, y_test = label[train_index], label[test_index]\n",
    "    # 학습 및 예측\n",
    "    dt_clf.fit(X_train, y_train)\n",
    "    pred = dt_clf.predict(X_test)\n",
    "    n_iter += 1\n",
    "    # 반복 시마다 정확도 측정\n",
    "    accuracy = np.round(accuracy_score(y_test, pred, 4))\n",
    "    train_size = X_train.shape[0]\n",
    "    test_size = X_test.shape[0]\n",
    "    print(\"\\n{0} 교차 검증 정확도 :{1}, 학습 데이터 크기: {2}, 검증 데이터 크기: {3}\".format(n_iter, accuracy, train_size, test_size))\n",
    "    print(\"#{0} 검증 세트 인덱스:{1}\".format(n_iter, test_index))\n",
    "    cv_accuracy.append(accuracy)\n",
    "          \n",
    "# 개별 iteration 별 정확도를 합하여 평균 정확도 계산\n",
    "print(\"\\n## 평균 검증 정확도:\", np.mean(cv_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Stratified KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    50\n",
       "1    50\n",
       "0    50\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "iris = load_iris()\n",
    "iris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "iris_df['label'] = iris.target\n",
    "iris_df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 아래처럼 정렬된 데이터를 고르게 분포하지 않고 학습을 하게 된다면 절대 결과를 예측하지 못한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## 교차검증: 1\n",
      "학습 레이블 데이터 분포:\n",
      " 2    50\n",
      "1    50\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포:\n",
      " 0    50\n",
      "Name: label, dtype: int64 \n",
      "\n",
      "\n",
      "## 교차검증: 2\n",
      "학습 레이블 데이터 분포:\n",
      " 2    50\n",
      "0    50\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포:\n",
      " 1    50\n",
      "Name: label, dtype: int64 \n",
      "\n",
      "\n",
      "## 교차검증: 3\n",
      "학습 레이블 데이터 분포:\n",
      " 1    50\n",
      "0    50\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포:\n",
      " 2    50\n",
      "Name: label, dtype: int64 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=3)\n",
    "n_iter = 0\n",
    "for train_index, test_index in kfold.split(iris_df):\n",
    "    n_iter += 1\n",
    "    label_train = iris_df[\"label\"].iloc[train_index]\n",
    "    label_test = iris_df[\"label\"].iloc[test_index]\n",
    "    print(\"## 교차검증: {0}\".format(n_iter))\n",
    "    print(\"학습 레이블 데이터 분포:\\n\", label_train.value_counts())\n",
    "    print(\"검증 레이블 데이터 분포:\\n\", label_test.value_counts(), \"\\n\\n\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### StraitifiedKFold 는 위와 같은 현상을 해결해준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## 교차검증: 1\n",
      "학습 레이블 데이터 분포: \n",
      " 2    34\n",
      "1    33\n",
      "0    33\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포: \n",
      " 2    34\n",
      "1    33\n",
      "0    33\n",
      "Name: label, dtype: int64\n",
      "## 교차검증: 2\n",
      "학습 레이블 데이터 분포: \n",
      " 1    34\n",
      "2    33\n",
      "0    33\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포: \n",
      " 1    34\n",
      "2    33\n",
      "0    33\n",
      "Name: label, dtype: int64\n",
      "## 교차검증: 3\n",
      "학습 레이블 데이터 분포: \n",
      " 0    34\n",
      "2    33\n",
      "1    33\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포: \n",
      " 0    34\n",
      "2    33\n",
      "1    33\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skf = StratifiedKFold(n_splits=3)\n",
    "n_iter = 0\n",
    "\n",
    "for train_index, test_index in skf.split(iris_df, iris_df[\"label\"]):\n",
    "    n_iter += 1\n",
    "    label_train = iris_df[\"label\"].iloc[train_index]\n",
    "    label_test = iris_df['label'].iloc[test_index]\n",
    "    print(\"## 교차검증: {0}\".format(n_iter))\n",
    "    print(\"학습 레이블 데이터 분포: \\n\", label_train.value_counts())\n",
    "    print(\"검증 레이블 데이터 분포: \\n\", label_train.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]]\n",
      "[0 0 0 0 0]\n",
      "\n",
      "1 교차 검증 정확도 :0.98, 학습 데이터 크기: 100, 검증 데이터 크기: 50\n",
      "\n",
      "1 검증 세트 인덱스: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  50\n",
      "  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65  66 100 101\n",
      " 102 103 104 105 106 107 108 109 110 111 112 113 114 115]\n",
      "\n",
      "1 검증 세트 데이터: [[5.1 3.5 1.4 0.3]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [5.4 3.4 1.7 0.2]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [4.6 3.6 1.  0.2]\n",
      " [5.1 3.3 1.7 0.5]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [5.  3.  1.6 0.2]\n",
      " [5.  3.4 1.6 0.4]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [5.2 3.4 1.4 0.2]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [5.2 4.1 1.5 0.1]\n",
      " [5.5 4.2 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.2]\n",
      " [5.  3.2 1.2 0.2]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [4.9 3.6 1.4 0.1]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [5.  3.5 1.3 0.3]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [5.  3.5 1.6 0.6]\n",
      " [5.1 3.8 1.9 0.4]\n",
      " [4.8 3.  1.4 0.3]\n",
      " [5.1 3.8 1.6 0.2]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [5.3 3.7 1.5 0.2]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [5.8 2.7 4.1 1. ]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [5.9 3.2 4.8 1.8]\n",
      " [6.1 2.8 4.  1.3]\n",
      " [6.3 2.5 4.9 1.5]\n",
      " [6.1 2.8 4.7 1.2]\n",
      " [6.4 2.9 4.3 1.3]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [6.7 3.  5.  1.7]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [5.7 2.6 3.5 1. ]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [5.5 2.4 3.7 1. ]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [6.  2.7 5.1 1.6]\n",
      " [5.4 3.  4.5 1.5]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [6.7 3.1 4.7 1.5]\n",
      " [6.3 2.3 4.4 1.3]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [5.5 2.5 4.  1.3]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [6.1 3.  4.6 1.4]\n",
      " [5.8 2.6 4.  1.2]\n",
      " [5.  2.3 3.3 1. ]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [5.7 3.  4.2 1.2]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [6.2 2.9 4.3 1.3]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [5.7 2.8 4.1 1.3]\n",
      " [6.5 3.  5.5 1.8]\n",
      " [7.7 3.8 6.7 2.2]\n",
      " [7.7 2.6 6.9 2.3]\n",
      " [6.  2.2 5.  1.5]\n",
      " [6.9 3.2 5.7 2.3]\n",
      " [5.6 2.8 4.9 2. ]\n",
      " [7.7 2.8 6.7 2. ]\n",
      " [6.3 2.7 4.9 1.8]\n",
      " [6.7 3.3 5.7 2.1]\n",
      " [7.2 3.2 6.  1.8]\n",
      " [6.2 2.8 4.8 1.8]\n",
      " [6.1 3.  4.9 1.8]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [7.2 3.  5.8 1.6]\n",
      " [7.4 2.8 6.1 1.9]\n",
      " [7.9 3.8 6.4 2. ]\n",
      " [6.4 2.8 5.6 2.2]\n",
      " [6.3 2.8 5.1 1.5]\n",
      " [6.1 2.6 5.6 1.4]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [6.3 3.4 5.6 2.4]\n",
      " [6.4 3.1 5.5 1.8]\n",
      " [6.  3.  4.8 1.8]\n",
      " [6.9 3.1 5.4 2.1]\n",
      " [6.7 3.1 5.6 2.4]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [6.5 3.  5.2 2. ]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [5.9 3.  5.1 1.8]]\n",
      "\n",
      "2 교차 검증 정확도 :0.94, 학습 데이터 크기: 100, 검증 데이터 크기: 50\n",
      "\n",
      "2 검증 세트 인덱스: [ 17  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  67\n",
      "  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82 116 117 118\n",
      " 119 120 121 122 123 124 125 126 127 128 129 130 131 132]\n",
      "\n",
      "2 검증 세트 데이터: [[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [4.3 3.  1.1 0.1]\n",
      " [5.8 4.  1.2 0.2]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [5.4 3.9 1.3 0.4]\n",
      " [4.9 3.1 1.5 0.2]\n",
      " [5.  3.2 1.2 0.2]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [4.9 3.6 1.4 0.1]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [5.  3.5 1.3 0.3]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [5.  3.5 1.6 0.6]\n",
      " [5.1 3.8 1.9 0.4]\n",
      " [4.8 3.  1.4 0.3]\n",
      " [5.1 3.8 1.6 0.2]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [5.3 3.7 1.5 0.2]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [7.  3.2 4.7 1.4]\n",
      " [6.4 3.2 4.5 1.5]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [6.5 2.8 4.6 1.5]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [6.6 2.9 4.6 1.3]\n",
      " [5.2 2.7 3.9 1.4]\n",
      " [5.  2.  3.5 1. ]\n",
      " [5.9 3.  4.2 1.5]\n",
      " [6.  2.2 4.  1. ]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [5.6 3.  4.5 1.5]\n",
      " [6.  2.7 5.1 1.6]\n",
      " [5.4 3.  4.5 1.5]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [6.7 3.1 4.7 1.5]\n",
      " [6.3 2.3 4.4 1.3]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [5.5 2.5 4.  1.3]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [6.1 3.  4.6 1.4]\n",
      " [5.8 2.6 4.  1.2]\n",
      " [5.  2.3 3.3 1. ]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [5.7 3.  4.2 1.2]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [6.2 2.9 4.3 1.3]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [5.7 2.8 4.1 1.3]\n",
      " [6.3 3.3 6.  2.5]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [7.1 3.  5.9 2.1]\n",
      " [6.3 2.9 5.6 1.8]\n",
      " [6.5 3.  5.8 2.2]\n",
      " [7.6 3.  6.6 2.1]\n",
      " [4.9 2.5 4.5 1.7]\n",
      " [7.3 2.9 6.3 1.8]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [7.2 3.6 6.1 2.5]\n",
      " [6.5 3.2 5.1 2. ]\n",
      " [6.4 2.7 5.3 1.9]\n",
      " [6.8 3.  5.5 2.1]\n",
      " [5.7 2.5 5.  2. ]\n",
      " [5.8 2.8 5.1 2.4]\n",
      " [6.4 3.2 5.3 2.3]\n",
      " [6.3 2.8 5.1 1.5]\n",
      " [6.1 2.6 5.6 1.4]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [6.3 3.4 5.6 2.4]\n",
      " [6.4 3.1 5.5 1.8]\n",
      " [6.  3.  4.8 1.8]\n",
      " [6.9 3.1 5.4 2.1]\n",
      " [6.7 3.1 5.6 2.4]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [6.5 3.  5.2 2. ]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [5.9 3.  5.1 1.8]]\n",
      "\n",
      "3 교차 검증 정확도 :0.98, 학습 데이터 크기: 100, 검증 데이터 크기: 50\n",
      "\n",
      "3 검증 세트 인덱스: [ 34  35  36  37  38  39  40  41  42  43  44  45  46  47  48  49  83  84\n",
      "  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 133 134 135\n",
      " 136 137 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "\n",
      "3 검증 세트 데이터: [[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [4.3 3.  1.1 0.1]\n",
      " [5.8 4.  1.2 0.2]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [5.4 3.9 1.3 0.4]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [5.4 3.4 1.7 0.2]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [4.6 3.6 1.  0.2]\n",
      " [5.1 3.3 1.7 0.5]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [5.  3.  1.6 0.2]\n",
      " [5.  3.4 1.6 0.4]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [5.2 3.4 1.4 0.2]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [5.2 4.1 1.5 0.1]\n",
      " [5.5 4.2 1.4 0.2]\n",
      " [7.  3.2 4.7 1.4]\n",
      " [6.4 3.2 4.5 1.5]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [6.5 2.8 4.6 1.5]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [6.6 2.9 4.6 1.3]\n",
      " [5.2 2.7 3.9 1.4]\n",
      " [5.  2.  3.5 1. ]\n",
      " [5.9 3.  4.2 1.5]\n",
      " [6.  2.2 4.  1. ]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [5.6 3.  4.5 1.5]\n",
      " [5.8 2.7 4.1 1. ]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [5.9 3.2 4.8 1.8]\n",
      " [6.1 2.8 4.  1.3]\n",
      " [6.3 2.5 4.9 1.5]\n",
      " [6.1 2.8 4.7 1.2]\n",
      " [6.4 2.9 4.3 1.3]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [6.7 3.  5.  1.7]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [5.7 2.6 3.5 1. ]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [5.5 2.4 3.7 1. ]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [6.3 3.3 6.  2.5]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [7.1 3.  5.9 2.1]\n",
      " [6.3 2.9 5.6 1.8]\n",
      " [6.5 3.  5.8 2.2]\n",
      " [7.6 3.  6.6 2.1]\n",
      " [4.9 2.5 4.5 1.7]\n",
      " [7.3 2.9 6.3 1.8]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [7.2 3.6 6.1 2.5]\n",
      " [6.5 3.2 5.1 2. ]\n",
      " [6.4 2.7 5.3 1.9]\n",
      " [6.8 3.  5.5 2.1]\n",
      " [5.7 2.5 5.  2. ]\n",
      " [5.8 2.8 5.1 2.4]\n",
      " [6.4 3.2 5.3 2.3]\n",
      " [6.5 3.  5.5 1.8]\n",
      " [7.7 3.8 6.7 2.2]\n",
      " [7.7 2.6 6.9 2.3]\n",
      " [6.  2.2 5.  1.5]\n",
      " [6.9 3.2 5.7 2.3]\n",
      " [5.6 2.8 4.9 2. ]\n",
      " [7.7 2.8 6.7 2. ]\n",
      " [6.3 2.7 4.9 1.8]\n",
      " [6.7 3.3 5.7 2.1]\n",
      " [7.2 3.2 6.  1.8]\n",
      " [6.2 2.8 4.8 1.8]\n",
      " [6.1 3.  4.9 1.8]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [7.2 3.  5.8 1.6]\n",
      " [7.4 2.8 6.1 1.9]\n",
      " [7.9 3.8 6.4 2. ]\n",
      " [6.4 2.8 5.6 2.2]]\n",
      "\n",
      "## 교차 검증별 정확도: [0.98 0.94 0.98]\n",
      "## 평균 검증 정확도: 0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "dt_clf = DecisionTreeClassifier(random_state=156)\n",
    "\n",
    "skfold = StratifiedKFold(n_splits=3)\n",
    "n_iter = 0\n",
    "cv_accuracy = []\n",
    "\n",
    "print(features[0:5])\n",
    "print(label[0:5])\n",
    "\n",
    "# StratifiedKFold 의 split() 호출시 반드시 레이블 데이터 세트도 추가 입력 필요\n",
    "for train_index, test_index in skfold.split(features, label):\n",
    "    # split() 으로 반환된 인덱스를 이용해 학습용, 검증용 테스트 데이터 추출\n",
    "    X_train, X_test = features[train_index], features[test_index]\n",
    "    y_train, y_test = label[train_index], label[test_index]\n",
    "    # 학습 및 예측\n",
    "    dt_clf.fit(X_train, y_train)\n",
    "    pred = dt_clf.predict(X_test)\n",
    "    \n",
    "    # 반복 시마다 정확도 측정\n",
    "    n_iter += 1\n",
    "    accuracy = np.round(accuracy_score(y_test, pred), 4)\n",
    "    train_size = X_train.shape[0]\n",
    "    test_size = X_test.shape[0]\n",
    "    print(\"\\n{0} 교차 검증 정확도 :{1}, 학습 데이터 크기: {2}, 검증 데이터 크기: {3}\"\n",
    "             .format(n_iter, accuracy, train_size, test_size))\n",
    "    print(\"\\n{0} 검증 세트 인덱스: {1}\".format(n_iter, test_index))\n",
    "    print(\"\\n{0} 검증 세트 데이터: {1}\".format(n_iter, X_train))\n",
    "    cv_accuracy.append(accuracy)\n",
    "    \n",
    "# 교차 검증별 정확도 및 평균 정확도 계산\n",
    "print(\"\\n## 교차 검증별 정확도:\", np.round(cv_accuracy, 4))\n",
    "print(\"## 평균 검증 정확도:\", np.mean(cv_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - 교차 검증을 보다 간편하게 - cross_val_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "교차 검증별 정확도: [0.98 0.94 0.98]\n",
      "평균 검증 정확도: 0.9667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris_data = load_iris()\n",
    "dt_clf = DecisionTreeClassifier(random_state=156)\n",
    "\n",
    "data = iris_data.data\n",
    "label = iris_data.target\n",
    "\n",
    "# 성능 지표는 정확도(accuracy), 교차 검증 세트는 3개\n",
    "scores = cross_val_score(dt_clf, data, label, scoring=\"accuracy\", cv=3)\n",
    "print(\"교차 검증별 정확도:\", np.round(scores, 4))\n",
    "print(\"평균 검증 정확도:\", np.round(np.mean(scores), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. GridSearechCV - 교차 검증과 최적 하이퍼 파라미터 튜닝을 한 번에"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 데이터를 로딩하고 학습 데이터와 테스트 데이터 분리\n",
    "iris_data = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris_data.data, iris_data.target, test_size = 0.2, random_state=121)\n",
    "\n",
    "dtree = DecisionTreeClassifier()\n",
    "\n",
    "# 파라미터를 딕셔너리 형태로 설정\n",
    "parameters = {'max_depth':[1, 2, 3], 'min_samples_split':[2, 3]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 2}</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 3}</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 2}</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>3</td>\n",
       "      <td>0.925</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 3}</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>3</td>\n",
       "      <td>0.925</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'max_depth': 3, 'min_samples_split': 2}</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.975</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'max_depth': 3, 'min_samples_split': 3}</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.975</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     params  mean_test_score  rank_test_score  \\\n",
       "0  {'max_depth': 1, 'min_samples_split': 2}         0.700000                5   \n",
       "1  {'max_depth': 1, 'min_samples_split': 3}         0.700000                5   \n",
       "2  {'max_depth': 2, 'min_samples_split': 2}         0.958333                3   \n",
       "3  {'max_depth': 2, 'min_samples_split': 3}         0.958333                3   \n",
       "4  {'max_depth': 3, 'min_samples_split': 2}         0.975000                1   \n",
       "5  {'max_depth': 3, 'min_samples_split': 3}         0.975000                1   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  \n",
       "0              0.700                0.7               0.70  \n",
       "1              0.700                0.7               0.70  \n",
       "2              0.925                1.0               0.95  \n",
       "3              0.925                1.0               0.95  \n",
       "4              0.975                1.0               0.95  \n",
       "5              0.975                1.0               0.95  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# param_grid 의 하이퍼 파라미터를 3개의 train, test set fold 로 나누어 테스트 수행 설정.\n",
    "# refit=True 가 default임. True 이면 가장 좋은 파라미터 설정으로 재학습시킴.\n",
    "grid_dtree = GridSearchCV(dtree, param_grid = parameters, cv=3, refit=True)\n",
    "\n",
    "# 붓꽃 학습 데이터로 param_grid 의 하이퍼 파라미터를 순차적으로 학습/ 평가.\n",
    "grid_dtree.fit(X_train, y_train)\n",
    "\n",
    "# GridSearchCV 결과를 추출해 DataFrame 으로 변환\n",
    "scores_df = pd.DataFrame(grid_dtree.cv_results_)\n",
    "scores_df[[\"params\", \"mean_test_score\", \"rank_test_score\", \"split0_test_score\", \"split1_test_score\", \"split2_test_score\"]]\n",
    "# 아래 코드는 1위의 성능을 보인 하이퍼파라미터의 데이터프레임을 보여주는 코드이다.\n",
    "# scores_df[scores_df.rank_test_score == 1][[\"params\", \"mean_test_score\", \"rank_test_score\", \"split0_test_score\", \"split1_test_score\", \"split2_test_score\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV 최적 파라미터: {'max_depth': 3, 'min_samples_split': 2}\n",
      "GridSearchCV 최고 정확도:0.9750\n"
     ]
    }
   ],
   "source": [
    "print(\"GridSearchCV 최적 파라미터:\", grid_dtree.best_params_)\n",
    "print(\"GridSearchCV 최고 정확도:{0:.4f}\".format(grid_dtree.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 데이터 세트 정확도: 0.9667\n"
     ]
    }
   ],
   "source": [
    "# GridSearchCV 의 refit 으로 이미 학습된 estimator 반환\n",
    "estimator = grid_dtree.best_estimator_\n",
    "\n",
    "# GridSearchCV 의 best_estimator_ 는 이미 최적 학습이 됐으므로 별도 학습이 필요 없음\n",
    "pred = estimator.predict(X_test)\n",
    "print(\"테스트 데이터 세트 정확도: {0:.4f}\".format(accuracy_score(y_test, pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 데이터 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - 레이블 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인코딩 변환값: [0 1 4 5 3 2 2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "items = [\"TV\", \"냉장고\", \"전자레인지\", \"컴퓨터\", \"선풍기\", \"믹서\", \"믹서\"]\n",
    "\n",
    "# LabelEncoder 를 객체로 생성한 후, fit() 과 transform() 으로 레이블 인코딩 수행.\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(items)\n",
    "labels = encoder.transform(items)\n",
    "print(\"인코딩 변환값:\", labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인코딩 클래스: ['TV' '냉장고' '믹서' '선풍기' '전자레인지' '컴퓨터']\n"
     ]
    }
   ],
   "source": [
    "print(\"인코딩 클래스:\", encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "디코딩 원본값: ['전자레인지' '컴퓨터' '믹서' 'TV' '냉장고' '냉장고' '선풍기']\n"
     ]
    }
   ],
   "source": [
    "print(\"디코딩 원본값:\", encoder.inverse_transform([4, 5, 2, 0, 1, 1, 3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - 원-핫 인코딩 (One-Hot Encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원-핫 인코딩 데이터\n",
      "[[1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]]\n",
      "원-핫 인코딩 데이터 차원\n",
      "(8, 6)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "\n",
    "items = [\"TV\", \"냉장고\", \"전자레인지\", \"컴퓨터\", \"선풍기\", \"선풍기\", \"믹서\", \"믹서\"]\n",
    "\n",
    "# 먼저 숫자 값으로 변환을 위해 LabelEncoder 로 변환합니다.\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(items)\n",
    "labels = encoder.transform(items)\n",
    "# 2차원 데이터로 반환합니다.\n",
    "labels = labels.reshape(-1, 1)\n",
    "\n",
    "# 원-핫 인코딩을 적용합니다.\n",
    "oh_encoder = OneHotEncoder()\n",
    "oh_encoder.fit(labels)\n",
    "oh_labels = oh_encoder.transform(labels)\n",
    "print(\"원-핫 인코딩 데이터\")\n",
    "print(oh_labels.toarray())\n",
    "print(\"원-핫 인코딩 데이터 차원\")\n",
    "print(oh_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_TV</th>\n",
       "      <th>item_냉장고</th>\n",
       "      <th>item_믹서</th>\n",
       "      <th>item_선풍기</th>\n",
       "      <th>item_전자레인지</th>\n",
       "      <th>item_컴퓨터</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_TV  item_냉장고  item_믹서  item_선풍기  item_전자레인지  item_컴퓨터\n",
       "0        1         0        0         0           0         0\n",
       "1        0         1        0         0           0         0\n",
       "2        0         0        0         0           1         0\n",
       "3        0         0        0         0           0         1\n",
       "4        0         0        0         1           0         0\n",
       "5        0         0        0         1           0         0\n",
       "6        0         0        1         0           0         0\n",
       "7        0         0        1         0           0         0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'item': [\"TV\", \"냉장고\", \"전자레인지\", \"컴퓨터\", \"선풍기\", \"선풍기\", \"믹서\", \"믹서\"]})\n",
    "pd.get_dummies(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - 피처 스케일링과 정규화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature 들의 평균값\n",
      "sepal length (cm)    5.843333\n",
      "sepal width (cm)     3.057333\n",
      "petal length (cm)    3.758000\n",
      "petal width (cm)     1.199333\n",
      "dtype: float64\n",
      "\n",
      "feature 들의 분산 값\n",
      "sepal length (cm)    0.685694\n",
      "sepal width (cm)     0.189979\n",
      "petal length (cm)    3.116278\n",
      "petal width (cm)     0.581006\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "\n",
    "# 붓꽃 데이터 세트를 로딩하고 DataFrame 으로 변환합니다.\n",
    "iris = load_iris()\n",
    "iris_data = iris.data\n",
    "iris_df = pd.DataFrame(data=iris_data, columns=iris.feature_names)\n",
    "\n",
    "print(\"feature 들의 평균값\")\n",
    "print(iris_df.mean())\n",
    "print(\"\\nfeature 들의 분산 값\")\n",
    "print(iris_df.var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature 들의 평균값\n",
      "sepal length (cm)   -1.690315e-15\n",
      "sepal width (cm)    -1.842970e-15\n",
      "petal length (cm)   -1.698641e-15\n",
      "petal width (cm)    -1.409243e-15\n",
      "dtype: float64\n",
      "\n",
      "feature 들의 분산 값\n",
      "sepal length (cm)    1.006711\n",
      "sepal width (cm)     1.006711\n",
      "petal length (cm)    1.006711\n",
      "petal width (cm)     1.006711\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# StandardScaler 객체 생성\n",
    "scaler = StandardScaler()\n",
    "# StandardScaler로 데이터 세트 변환, fit() 과 transform() 호출.\n",
    "scaler.fit(iris_df)\n",
    "iris_scaled = scaler.transform(iris_df)  # NumPy ndarray 로 반환됨\n",
    "\n",
    "iris_df_scaled = pd.DataFrame(data=iris_scaled, columns=iris.feature_names) # 데이터 프레임으로 변환\n",
    "print(\"feature 들의 평균값\")\n",
    "print(iris_df_scaled.mean())\n",
    "print(\"\\nfeature 들의 분산 값\")\n",
    "print(iris_df_scaled.var())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - MinMacScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature 들의 최솟값\n",
      "sepal length (cm)    0.0\n",
      "sepal width (cm)     0.0\n",
      "petal length (cm)    0.0\n",
      "petal width (cm)     0.0\n",
      "dtype: float64\n",
      "\n",
      "feature 들의 최댓값\n",
      "sepal length (cm)    1.0\n",
      "sepal width (cm)     1.0\n",
      "petal length (cm)    1.0\n",
      "petal width (cm)     1.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# MinMaxScaler 객체 생성\n",
    "scaler = MinMaxScaler()\n",
    "# MinMaxScaler 로 데이터 세트 변환, fit() 과 transform() 호출.\n",
    "scaler.fit(iris_df)\n",
    "iris_scaled = scaler.transform(iris_df)  # ndarray 로 반환됨.\n",
    "\n",
    "iris_df_scaled = pd.DataFrame(data=iris_scaled, columns=iris.feature_names)  # DataFrame 으로 변환.\n",
    "print(\"feature 들의 최솟값\")\n",
    "print(iris_df_scaled.min())\n",
    "print(\"\\nfeature 들의 최댓값\")\n",
    "print(iris_df_scaled.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - 학습 데이터와 테스트 데이터의 스케일링 변환 시 유의점\n",
    "- 학습 데이터 세트로 Scaler 객체의 fit() 과 transform() 를 적용하면 테스트 데이터 세트도 학습 데이터 세트로 fit 한 상태로 transform 을 해야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 모듈 임포드 & 변수 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    " # Scaler 객체의 fit() 과 transform() 메소드는 이차원 이상 데이터만 가능하므로 reshape 을 해준다.\n",
    "train_array = np.arange(0, 11).reshape(-1, 1)\n",
    "test_array = np.arange(0, 6).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 잘못된 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_scaled: [0.  0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1. ]\n",
      "test_scaled: [0.  0.2 0.4 0.6 0.8 1. ]\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "scaler.fit(train_array)\n",
    "\n",
    "train_scaled = scaler.transform(train_array)\n",
    "\n",
    "print(\"train_scaled:\", np.round(train_scaled.reshape(-1), 2))\n",
    "\n",
    "# 아래처럼 테스트 데이터 세트로 또 fit 하면 안됨.\n",
    "scaler.fit(test_array)\n",
    "\n",
    "test_scaled = scaler.transform(test_array)\n",
    "\n",
    "print(\"test_scaled:\", np.round(test_scaled.reshape(-1), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 올바른 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_scaled: [0.  0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1. ]\n",
      "test_scaled: [0.  0.1 0.2 0.3 0.4 0.5]\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(train_array)\n",
    "train_scaled = scaler.transform(train_array)\n",
    "\n",
    "test_scaled = scaler.transform(test_array)\n",
    "\n",
    "print(\"train_scaled:\", np.round(train_scaled.reshape(-1), 2))\n",
    "print(\"test_scaled:\", np.round(test_scaled.reshape(-1), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 평가\n",
    "- 정확도 (accuracy)\n",
    "- 오차 행렬\n",
    "- 정밀도와 재현율\n",
    "- F1 스코어\n",
    "- ROC 곡선과 AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "class MyDummyClassifier(BaseEstimator):\n",
    "    def fit(self, X, y=None):  # 학습을 하지 않음.\n",
    "        pass\n",
    "    def predict(self, X):  # 특정 알고리즘으로도 정확도가 높게 나옴.\n",
    "        pred = np.zeros((X.shape[0], 1))\n",
    "        for i in range(X.shape[0]):\n",
    "            if X[\"Sex\"].iloc[i] == 1:\n",
    "                pred[i] = 0\n",
    "            else:\n",
    "                pred[i] = 1\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단순 알고리즘만으로 나온 정확도: 0.7877\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def sex_to_num(x):\n",
    "    if x == \"male\": return 1\n",
    "    if x == \"female\": return 0\n",
    "\n",
    "titanic_df = pd.read_csv(\"./titanic_survivor_prediction/titanic_train.csv\")\n",
    "titanic_df[\"Sex\"] = titanic_df[\"Sex\"].apply(lambda x : sex_to_num(x))\n",
    "y_titanic_df = titanic_df[\"Survived\"]\n",
    "x_titanic_df = titanic_df.drop(\"Survived\", axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_titanic_df, y_titanic_df, \n",
    "                                                    test_size=0.2, random_state=0)\n",
    "\n",
    "myclf = MyDummyClassifier()\n",
    "mypredictions = myclf.predict(X_test)\n",
    "print(\"단순 알고리즘만으로 나온 정확도:\", np.round(accuracy_score(y_test, mypredictions), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - 불균형한 데이터셋을 사용하면 생기는 일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label testset shape: (450,)\n",
      "testset label 0 and 1 distribution\n",
      " 0    405\n",
      "1     45\n",
      "dtype: int64\n",
      "accuracy score is: 0.9\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class MyFakeClassifier(BaseEstimator):\n",
    "    def fit(selx, X, y):\n",
    "        pass\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return np.zeros((len(X), 1), dtype=bool)\n",
    "    \n",
    "digits = load_digits()\n",
    "# 7 만 True 로 하고, 나머지는 다 False 로 하여 불균형한 데이터셋으로 만든다.\n",
    "y = (digits.target == 7).astype(int)\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits.data, y, random_state=11)\n",
    "\n",
    "print(\"label testset shape:\", y_test.shape)\n",
    "print(\"testset label 0 and 1 distribution\\n\", pd.Series(y_test).value_counts())\n",
    "\n",
    "fakeclf = MyFakeClassifier()\n",
    "fakepred = fakeclf.predict(X_test)\n",
    "# 불균형한 데이터셋으로는 단순 알고리즘만으로도 높은 정확도를 만들어 낼 수 있다.\n",
    "print(\"accuracy score is:\", np.round(accuracy_score(y_test, fakepred), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - 오차행렬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[405,   0],\n",
       "       [ 45,   0]], dtype=int64)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, fakepred)\n",
    "# TN - [0, 0], FP - [0, 1], FN - [1, 0], TP - [1, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - 정밀도와 재현율\n",
    "- 정밀도 = TP / (FP + TP) -> Nagative 를 Postivie 로 잘못 판단하는지가 중요할 경우 사용됨.  \n",
    "예) 스팸이 아닌데 스팸메일로 착각하여 필터로 걸러서 메일을 보내지 않는 경우.  \n",
    "- 재현율 = TP / (FN + TP) -> Positive 를 Nagative 로 잘못 판단하는지가 중요할 경우 사용됨.  \n",
    "예) 암인데 암이 아니라고 착각하는 치명적인 실수를 하는 경우."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "def get_clf_eval(y_test, pred):\n",
    "    confusion = confusion_matrix(y_test, pred)  # 오차행렬\n",
    "    accuracy = accuracy_score(y_test, pred)  # 정확도\n",
    "    precision = precision_score(y_test, pred)  # 정밀도\n",
    "    recall = recall_score(y_test, pred)  # 재현율\n",
    "    print(confusion)\n",
    "    print(f\"accuracy(정확도): {accuracy}, precision(정밀도): {precision}, recall(재현율): {recall}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "# Null 처리\n",
    "def fillna(df):\n",
    "    df[\"Age\"].fillna(df[\"Age\"].mean(), inplace=True)\n",
    "    df[\"Cabin\"].fillna(\"N\", inplace=True)\n",
    "    df[\"Embarked\"].fillna(\"N\", inplace=True)\n",
    "    df[\"Fare\"].fillna(0, inplace=True)\n",
    "    return df\n",
    "\n",
    "# 불필요한 속성 제거\n",
    "def drop_features(df):\n",
    "    df.drop([\"PassengerId\", \"Name\", \"Ticket\"], axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "# 레이블 인코딩\n",
    "def format_features(df):\n",
    "    df[\"Cabin\"] = df[\"Cabin\"].str[:1]\n",
    "    features = [\"Cabin\", \"Sex\", \"Embarked\"]\n",
    "    for feature in features:\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        le = le.fit(df[feature])\n",
    "        df[feature] = le.transform(df[feature])\n",
    "    return df\n",
    "\n",
    "# 앞에서 정의한 메소드 호출\n",
    "def transform_features(df):\n",
    "    df = fillna(df)\n",
    "    df = drop_features(df)\n",
    "    df = format_features(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[104  14]\n",
      " [ 13  48]]\n",
      "accuracy(정확도): 0.8491620111731844, precision(정밀도): 0.7741935483870968, recall(재현율): 0.7868852459016393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\k58m\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "titanic_df = pd.read_csv(\"./titanic_survivor_prediction/titanic_train.csv\")\n",
    "y_titanic_df = titanic_df[\"Survived\"]\n",
    "x_titanic_df = titanic_df.drop(\"Survived\", axis=1)\n",
    "x_titanic_df = transform_features(x_titanic_df)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_titanic_df, y_titanic_df,\n",
    "                                                   test_size=0.2, random_state=11)\n",
    "\n",
    "lr_clf = LogisticRegression()\n",
    "\n",
    "lr_clf.fit(X_train, y_train)\n",
    "pred = lr_clf.predict(X_test)\n",
    "get_clf_eval(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - 정밀도 / 재현율 트레이드오프"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred_prob shape: (179, 2)\n",
      "pred_proba ex 3 :\n",
      " [[0.46175211 0.53824789]\n",
      " [0.87863924 0.12136076]\n",
      " [0.87717092 0.12282908]]\n",
      "두 개의 class 중에서 더 큰 확률을 클래스 값으로 예측:\n",
      " [[0.46175211 0.53824789 1.        ]\n",
      " [0.87863924 0.12136076 0.        ]\n",
      " [0.87717092 0.12282908 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "pred_proba = lr_clf.predict_proba(X_test)  # 레이블별 예측률을 반환함.\n",
    "pred = lr_clf.predict(X_test)\n",
    "print(\"pred_prob shape:\", pred_proba.shape)\n",
    "print(\"pred_proba ex 3 :\\n\", pred_proba[:3])\n",
    "# [[0.46175211 0.53824789]]  -> 레이블이 0일 확률 약 46%, 1일 확률 약 53%\n",
    "# predict 는 predict_proba 를 통해 반환됨.\n",
    "\n",
    "pred_proba_result = np.concatenate([prbed_proba, pred.reshape(-1, 1)], axis=1)\n",
    "print(\"두 개의 class 중에서 더 큰 확률을 클래스 값으로 예측:\\n\", pred_proba_result[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[104  14]\n",
      " [ 13  48]]\n",
      "accuracy(정확도): 0.8491620111731844, precision(정밀도): 0.7741935483870968, recall(재현율): 0.7868852459016393\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "custom_threshold = 0.5  # 임계값\n",
    "\n",
    "pred_proba_1 = pred_proba[:, 1].reshape(-1, 1)  # Index1 번째 값을 가져와 임계값으로 레이블 결정.\n",
    "\n",
    "binarizer = Binarizer(threshold=custom_threshold).fit(pred_proba_1)\n",
    "custom_predict = binarizer.transform(pred_proba_1)\n",
    "\n",
    "get_clf_eval(y_test, custom_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[98 20]\n",
      " [10 51]]\n",
      "accuracy(정확도): 0.8324022346368715, precision(정밀도): 0.7183098591549296, recall(재현율): 0.8360655737704918\n"
     ]
    }
   ],
   "source": [
    "custom_threshold = 0.4  # 임계값\n",
    "\n",
    "pred_proba_1 = pred_proba[:, 1].reshape(-1, 1)\n",
    "\n",
    "binarizer = Binarizer(threshold=custom_threshold).fit(pred_proba_1)\n",
    "custom_predict = binarizer.transform(pred_proba_1)\n",
    "\n",
    "get_clf_eval(y_test, custom_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "임곗값: 0.4\n",
      "[[98 20]\n",
      " [10 51]]\n",
      "accuracy(정확도): 0.8324022346368715, precision(정밀도): 0.7183098591549296, recall(재현율): 0.8360655737704918\n",
      "임곗값: 0.45\n",
      "[[103  15]\n",
      " [ 12  49]]\n",
      "accuracy(정확도): 0.8491620111731844, precision(정밀도): 0.765625, recall(재현율): 0.8032786885245902\n",
      "임곗값: 0.5\n",
      "[[104  14]\n",
      " [ 13  48]]\n",
      "accuracy(정확도): 0.8491620111731844, precision(정밀도): 0.7741935483870968, recall(재현율): 0.7868852459016393\n",
      "임곗값: 0.55\n",
      "[[109   9]\n",
      " [ 15  46]]\n",
      "accuracy(정확도): 0.8659217877094972, precision(정밀도): 0.8363636363636363, recall(재현율): 0.7540983606557377\n",
      "임곗값: 0.6\n",
      "[[112   6]\n",
      " [ 16  45]]\n",
      "accuracy(정확도): 0.8770949720670391, precision(정밀도): 0.8823529411764706, recall(재현율): 0.7377049180327869\n"
     ]
    }
   ],
   "source": [
    "thresholds = [0.4, 0.45, 0.5, 0.55, 0.6]\n",
    "\n",
    "# 임계값별로 정확도, 정밀도, 재현율을 구함\n",
    "def get_eval_by_threshold(y_test, pred_proba_1, thresholds):\n",
    "    for custom_threshold in thresholds:\n",
    "        binarizer = Binarizer(threshold=custom_threshold).fit(pred_proba_1)\n",
    "        custom_predict = binarizer.transform(pred_proba_1)\n",
    "        print(\"임곗값:\", custom_threshold)\n",
    "        get_clf_eval(y_test, custom_predict)\n",
    "        \n",
    "get_eval_by_threshold(y_test, pred_proba[:, 1].reshape(-1, 1), thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresholds shape: (143,)\n",
      "thresholds: [0.1  0.12 0.14 0.19 0.28 0.4  0.56 0.67 0.82 0.95]\n",
      "precisions: [0.39 0.44 0.47 0.54 0.65 0.73 0.84 0.95 0.96 1.  ]\n",
      "recalls:    [1.   0.97 0.9  0.9  0.9  0.84 0.75 0.61 0.38 0.15]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "pred_proba_class1 = lr_clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_test, pred_proba_class1)\n",
    "print(\"thresholds shape:\", thresholds.shape)\n",
    "\n",
    "thre_index = np.arange(0, thresholds.shape[0], 15)  # 15 단계씩 정밀도, 재현율을 구함\n",
    "\n",
    "print(\"thresholds:\", np.round(thresholds[thre_index], 2))\n",
    "print(\"precisions:\", np.round(precisions[thre_index], 2))\n",
    "print(\"recalls:   \", np.round(recalls[thre_index], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def precision_recall_curve_plot(y_test, pred_proba_c1):\n",
    "    precisions, recalls, thresholds = precision_recall_curve(y_test, pred_proba_c1)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    threshold_boundary = thresholds.shape[0]\n",
    "    # 정밀도는 점선으로 표현\n",
    "    plt.plot(thresholds, precisions[:threshold_boundary], linestyle=\"--\", label=\"precision\")\n",
    "    # 재현율은 실선으로 표현\n",
    "    plt.plot(thresholds, recalls[:threshold_boundary], label=\"recalls\")\n",
    "    \n",
    "    start, end = plt.xlim()\n",
    "    plt.xticks(np.round(np.arange(start, end, 0.1), 2))\n",
    "    \n",
    "    plt.xlabel(\"Threshold value\")\n",
    "    plt.ylabel(\"Precision and Recall Value\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    \n",
    "precision_recall_curve_plot(y_test, lr_clf.predict_proba(X_test)[:, 1])\n",
    "# 아래 그래프에서 교점에 해당하는 x 값이 가장 적절한 임계값임."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
